{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b12fa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Karakorum\n",
      "[nltk_data]     Traders\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\Karakorum Traders\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from urduhack.preprocessing import remove_punctuation\n",
    "from urduhack.preprocessing import normalize_whitespace\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9161b2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline =  (21, 3)\n"
     ]
    }
   ],
   "source": [
    "#Input Dataset\n",
    "df = pd.read_csv('News_Urdu_Dataset.csv')\n",
    "print(\"Headline = \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "631af35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = df.Headline\n",
    "data = mydata.tolist()\n",
    "sentence = ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f43c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be2b2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['عالمی', 'بینک', 'عسکریت', 'پسندی', 'سے', 'متاثرہ', 'خاندانوں', 'کی', 'معاونت', 'کرے', 'گا', 'مالی', 'سال', '2020', 'ریٹرن', 'فائل', 'کرنے', 'والوں', 'کی', 'تعداد', 'میں', '23', 'فیصد', 'کمی', 'جاپان', 'کو', 'سندھ', 'کے', 'خصوصی', 'اقتصادی', 'زون', 'میں', 'سرمایہ', 'کاری', 'کی', 'دعوت', 'برامدات', '767', 'فیصد', 'بڑھ', 'کر', 'ارب', '16', 'کروڑ', 'ڈالر', 'سے', 'زائد', 'کے', 'الیکٹرک', 'کو', 'اضافی', 'بجلی', 'گیس', 'کی', 'فراہمی', 'کے', 'قانونی', 'تقاضے', 'تعطل', 'کا', 'شکار', 'کھانے', 'پینے', 'کی', 'اشیا', 'کی', 'قیمتیں', 'سال', 'کی', 'بلند', 'ترین', 'سطح', 'پر', 'پہنچ', 'گئیں', 'اقوام', 'متحدہ', 'صنعتی', 'صارفین', 'کیلئے', 'بجلی', 'کے', 'پیک', 'ور', 'ٹیرف', 'اسکیم', 'کا', 'خاتمہ', 'اور', 'سبسڈی', 'منظور', 'پاکستان', 'میں', 'موبائل', 'کمپنیاں', 'مقامی', 'طور', 'پر', 'اسمبلنگ', 'کی', 'جانب', 'گامزن', 'گنے', 'کی', 'بروقت', 'کٹائی', 'سے', 'چینی', 'کی', 'قیمت', 'کم', 'ہو', 'کر', '85', 'روپے', 'فی', 'کلوگرام', 'تک', 'پہنچ', 'گئی', 'نومبر', 'میں', 'مہنگائی', 'معمولی', 'کمی', 'سے', '83', 'فیصد', 'رہی', 'ڈسکوز', 'کا', 'بجلی', 'کے', 'ٹیرف', 'میں', '86', 'پیسے', 'اضافے', 'کا', 'مطالبہ', 'جوہری', 'بجلی', 'گھر', 'کی', 'زمائش', 'کیلئے', 'ایندھن', 'کی', 'لوڈنگ', 'کا', 'غاز', 'پاک', 'سوزوکی', 'اور', 'انڈس', 'موٹرز', 'کی', 'گاڑیوں', 'کی', 'قیمتوں', 'میں', 'ایک', 'لاکھ', 'روپے', 'تک', 'اضافہ', 'نومبر', 'میں', 'ریونیو', 'کی', 'وصولی', '346', 'ارب', 'روپے', 'کے', 'ساتھ', 'ہدف', 'سے', 'قریب', 'رہی', 'نیشنل', 'بینک', 'میں', 'تقرریوں', 'کے', 'تھرڈ', 'پارٹی', 'ڈٹ', 'کی', 'سفارش', 'بٹ', 'کوائن', 'کی', 'قیمت', 'ریکارڈ', 'سطح', 'پر', 'پہنچ', 'گئی', 'پیٹرول', 'کی', 'قیمت', 'برقرار', 'ڈیزل', 'روپے', 'فی', 'لیٹر', 'مہنگا', 'ئل', 'کمپنیز', 'اور', 'ڈیلرز', 'کے', 'مارجن', 'میں', '16فیصد', 'تک', 'اضافہ', 'متوقع', 'مالی', 'سال', '2020', 'ملک', 'میں', 'موبائل', 'فون', 'کی', 'درامد', 'پر', '54', 'ارب', 'روپے', 'کی', 'ڈیوٹی', 'وصول', 'ازادی', 'کے', 'بعد', 'پہلی', 'مرتبہ', 'بھارتی', 'معیشت', 'کساد', 'بازاری', 'میں', 'داخل', 'وائرس', 'کے', 'پھیلا', 'میں', 'اضافہ', 'اور', 'پابندیاں', 'معاشی', 'بحالی', 'کیلئے', 'خطرہ']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization\n",
    "\n",
    "tokenized_word=word_tokenize(sentence)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74e9c166",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 4.42MB/s]                    \n",
      "2023-06-13 15:27:22 INFO: \"urdu\" is an alias for \"ur\"\n",
      "2023-06-13 15:27:22 INFO: Downloading default packages for language: ur (Urdu) ...\n",
      "2023-06-13 15:27:23 INFO: File exists: C:\\Users\\Karakorum Traders\\stanza_resources\\ur\\default.zip\n",
      "2023-06-13 15:27:25 INFO: Finished downloading models and saved to C:\\Users\\Karakorum Traders\\stanza_resources.\n",
      "2023-06-13 15:27:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 5.22MB/s]                    \n",
      "2023-06-13 15:27:26 INFO: Loading these models for language: ur (Urdu):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | udtb    |\n",
      "| pos       | udtb    |\n",
      "| lemma     | udtb    |\n",
      "| depparse  | udtb    |\n",
      "=======================\n",
      "\n",
      "2023-06-13 15:27:26 INFO: Using device: cpu\n",
      "2023-06-13 15:27:26 INFO: Loading: tokenize\n",
      "2023-06-13 15:27:26 INFO: Loading: pos\n",
      "2023-06-13 15:27:27 INFO: Loading: lemma\n",
      "2023-06-13 15:27:27 INFO: Loading: depparse\n",
      "2023-06-13 15:27:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('urdu')\n",
    "nlp = stanza.Pipeline('ur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53ca58bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"وائرس\",\n",
       "      \"lemma\": \"وائرس\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Acc|Gender=Masc|Number=Sing|Person=3\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"nmod\",\n",
       "      \"start_char\": 0,\n",
       "      \"end_char\": 5\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"کے\",\n",
       "      \"lemma\": \"کا\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"PSP\",\n",
       "      \"feats\": \"AdpType=Post|Case=Acc|Gender=Masc|Number=Sing\",\n",
       "      \"head\": 1,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 6,\n",
       "      \"end_char\": 8\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"پھیلا\",\n",
       "      \"lemma\": \"پھیلا\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Acc|Gender=Masc|Number=Sing|Person=3\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"obl\",\n",
       "      \"start_char\": 9,\n",
       "      \"end_char\": 14\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"میں\",\n",
       "      \"lemma\": \"میں\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"PSP\",\n",
       "      \"feats\": \"AdpType=Post\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 15,\n",
       "      \"end_char\": 18\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \"اضافہ\",\n",
       "      \"lemma\": \"اضافہ\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 19,\n",
       "      \"end_char\": 24\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"اور\",\n",
       "      \"lemma\": \"اور\",\n",
       "      \"upos\": \"CCONJ\",\n",
       "      \"xpos\": \"CC\",\n",
       "      \"head\": 7,\n",
       "      \"deprel\": \"cc\",\n",
       "      \"start_char\": 25,\n",
       "      \"end_char\": 28\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \"پابندیاں\",\n",
       "      \"lemma\": \"پابندی\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Nom|Gender=Masc|Number=Plur|Person=3\",\n",
       "      \"head\": 5,\n",
       "      \"deprel\": \"conj\",\n",
       "      \"start_char\": 29,\n",
       "      \"end_char\": 37\n",
       "    },\n",
       "    {\n",
       "      \"id\": 8,\n",
       "      \"text\": \"معاشی\",\n",
       "      \"lemma\": \"معاشی\",\n",
       "      \"upos\": \"ADJ\",\n",
       "      \"xpos\": \"JJ\",\n",
       "      \"feats\": \"Case=Acc\",\n",
       "      \"head\": 9,\n",
       "      \"deprel\": \"amod\",\n",
       "      \"start_char\": 38,\n",
       "      \"end_char\": 43\n",
       "    },\n",
       "    {\n",
       "      \"id\": 9,\n",
       "      \"text\": \"بحالی\",\n",
       "      \"lemma\": \"بحالی\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Acc|Gender=Masc|Number=Sing|Person=3\",\n",
       "      \"head\": 11,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 44,\n",
       "      \"end_char\": 49\n",
       "    },\n",
       "    {\n",
       "      \"id\": 10,\n",
       "      \"text\": \"کیلئے\",\n",
       "      \"lemma\": \"کیلئے\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"PSP\",\n",
       "      \"feats\": \"AdpType=Post\",\n",
       "      \"head\": 9,\n",
       "      \"deprel\": \"case\",\n",
       "      \"start_char\": 50,\n",
       "      \"end_char\": 55\n",
       "    },\n",
       "    {\n",
       "      \"id\": 11,\n",
       "      \"text\": \"خطرہ\",\n",
       "      \"lemma\": \"خطرہ\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NN\",\n",
       "      \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"start_char\": 56,\n",
       "      \"end_char\": 60\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(df.Headline[20])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ca561f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Words\n",
    "\n",
    "stopwords = ['لگے', 'ہیں', 'کی', 'کرنے', 'کو', 'آپ', 'میرا', 'کرو', 'کوئی', 'ہوا', 'ہونے', 'والا', 'تھا', 'رہتا', 'آیا', 'نہ', 'گئی', 'و', 'یہ','مجھے', 'رہی', 'نہیں', 'رہا', 'میں', 'ہوں', 'ہے', 'میرے', 'اپنی', 'کچھ', 'کر', 'میری', 'ہو', 'سے', 'رہے', 'کے', 'لیے', 'کا', 'اپنے', 'نے', 'ایک', 'گیا']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd474d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stop words\n",
    "\n",
    "word_tokens = word_tokenize(sentence)\n",
    "\n",
    "tokenized_word = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stopwords:\n",
    "        tokenized_word.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9eb660bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['عالمی',\n",
       " 'بینک',\n",
       " 'عسکریت',\n",
       " 'پسندی',\n",
       " 'متاثرہ',\n",
       " 'خاندانوں',\n",
       " 'معاونت',\n",
       " 'کرے',\n",
       " 'گا',\n",
       " 'مالی',\n",
       " 'سال',\n",
       " '2020',\n",
       " 'ریٹرن',\n",
       " 'فائل',\n",
       " 'والوں',\n",
       " 'تعداد',\n",
       " '23',\n",
       " 'فیصد',\n",
       " 'کمی',\n",
       " 'جاپان',\n",
       " 'سندھ',\n",
       " 'خصوصی',\n",
       " 'اقتصادی',\n",
       " 'زون',\n",
       " 'سرمایہ',\n",
       " 'کاری',\n",
       " 'دعوت',\n",
       " 'برامدات',\n",
       " '767',\n",
       " 'فیصد',\n",
       " 'بڑھ',\n",
       " 'ارب',\n",
       " '16',\n",
       " 'کروڑ',\n",
       " 'ڈالر',\n",
       " 'زائد',\n",
       " 'الیکٹرک',\n",
       " 'اضافی',\n",
       " 'بجلی',\n",
       " 'گیس',\n",
       " 'فراہمی',\n",
       " 'قانونی',\n",
       " 'تقاضے',\n",
       " 'تعطل',\n",
       " 'شکار',\n",
       " 'کھانے',\n",
       " 'پینے',\n",
       " 'اشیا',\n",
       " 'قیمتیں',\n",
       " 'سال',\n",
       " 'بلند',\n",
       " 'ترین',\n",
       " 'سطح',\n",
       " 'پر',\n",
       " 'پہنچ',\n",
       " 'گئیں',\n",
       " 'اقوام',\n",
       " 'متحدہ',\n",
       " 'صنعتی',\n",
       " 'صارفین',\n",
       " 'کیلئے',\n",
       " 'بجلی',\n",
       " 'پیک',\n",
       " 'ور',\n",
       " 'ٹیرف',\n",
       " 'اسکیم',\n",
       " 'خاتمہ',\n",
       " 'اور',\n",
       " 'سبسڈی',\n",
       " 'منظور',\n",
       " 'پاکستان',\n",
       " 'موبائل',\n",
       " 'کمپنیاں',\n",
       " 'مقامی',\n",
       " 'طور',\n",
       " 'پر',\n",
       " 'اسمبلنگ',\n",
       " 'جانب',\n",
       " 'گامزن',\n",
       " 'گنے',\n",
       " 'بروقت',\n",
       " 'کٹائی',\n",
       " 'چینی',\n",
       " 'قیمت',\n",
       " 'کم',\n",
       " '85',\n",
       " 'روپے',\n",
       " 'فی',\n",
       " 'کلوگرام',\n",
       " 'تک',\n",
       " 'پہنچ',\n",
       " 'نومبر',\n",
       " 'مہنگائی',\n",
       " 'معمولی',\n",
       " 'کمی',\n",
       " '83',\n",
       " 'فیصد',\n",
       " 'ڈسکوز',\n",
       " 'بجلی',\n",
       " 'ٹیرف',\n",
       " '86',\n",
       " 'پیسے',\n",
       " 'اضافے',\n",
       " 'مطالبہ',\n",
       " 'جوہری',\n",
       " 'بجلی',\n",
       " 'گھر',\n",
       " 'زمائش',\n",
       " 'کیلئے',\n",
       " 'ایندھن',\n",
       " 'لوڈنگ',\n",
       " 'غاز',\n",
       " 'پاک',\n",
       " 'سوزوکی',\n",
       " 'اور',\n",
       " 'انڈس',\n",
       " 'موٹرز',\n",
       " 'گاڑیوں',\n",
       " 'قیمتوں',\n",
       " 'لاکھ',\n",
       " 'روپے',\n",
       " 'تک',\n",
       " 'اضافہ',\n",
       " 'نومبر',\n",
       " 'ریونیو',\n",
       " 'وصولی',\n",
       " '346',\n",
       " 'ارب',\n",
       " 'روپے',\n",
       " 'ساتھ',\n",
       " 'ہدف',\n",
       " 'قریب',\n",
       " 'نیشنل',\n",
       " 'بینک',\n",
       " 'تقرریوں',\n",
       " 'تھرڈ',\n",
       " 'پارٹی',\n",
       " 'ڈٹ',\n",
       " 'سفارش',\n",
       " 'بٹ',\n",
       " 'کوائن',\n",
       " 'قیمت',\n",
       " 'ریکارڈ',\n",
       " 'سطح',\n",
       " 'پر',\n",
       " 'پہنچ',\n",
       " 'پیٹرول',\n",
       " 'قیمت',\n",
       " 'برقرار',\n",
       " 'ڈیزل',\n",
       " 'روپے',\n",
       " 'فی',\n",
       " 'لیٹر',\n",
       " 'مہنگا',\n",
       " 'ئل',\n",
       " 'کمپنیز',\n",
       " 'اور',\n",
       " 'ڈیلرز',\n",
       " 'مارجن',\n",
       " '16فیصد',\n",
       " 'تک',\n",
       " 'اضافہ',\n",
       " 'متوقع',\n",
       " 'مالی',\n",
       " 'سال',\n",
       " '2020',\n",
       " 'ملک',\n",
       " 'موبائل',\n",
       " 'فون',\n",
       " 'درامد',\n",
       " 'پر',\n",
       " '54',\n",
       " 'ارب',\n",
       " 'روپے',\n",
       " 'ڈیوٹی',\n",
       " 'وصول',\n",
       " 'ازادی',\n",
       " 'بعد',\n",
       " 'پہلی',\n",
       " 'مرتبہ',\n",
       " 'بھارتی',\n",
       " 'معیشت',\n",
       " 'کساد',\n",
       " 'بازاری',\n",
       " 'داخل',\n",
       " 'وائرس',\n",
       " 'پھیلا',\n",
       " 'اضافہ',\n",
       " 'اور',\n",
       " 'پابندیاں',\n",
       " 'معاشی',\n",
       " 'بحالی',\n",
       " 'کیلئے',\n",
       " 'خطرہ']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b96eff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 257 and  after 194 words in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "#Before and After Stop Words Removing\n",
    "\n",
    "print(f\"Before {len(word_tokens)} and  after {len(tokenized_word)} words in the vocabulary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cedf8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(e):\n",
    "  remove_punc = normalize_whitespace(remove_punctuation(e))\n",
    "  return [word for word in remove_punc.split() if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "263249c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [عالمی, بینک, عسکریت, پسندی, متاثرہ, خاندانوں,...\n",
      "1     [مالی, سال, 2020, ریٹرن, فائل, والوں, تعداد, 2...\n",
      "2     [جاپان, سندھ, خصوصی, اقتصادی, زون, سرمایہ, کار...\n",
      "3     [برامدات, 767, فیصد, بڑھ, ارب, 16, کروڑ, ڈالر,...\n",
      "4     [الیکٹرک, اضافی, بجلی, گیس, فراہمی, قانونی, تق...\n",
      "5     [کھانے, پینے, اشیا, قیمتیں, سال, بلند, ترین, س...\n",
      "6     [صنعتی, صارفین, کیلئے, بجلی, پیک, ور, ٹیرف, اس...\n",
      "7     [پاکستان, موبائل, کمپنیاں, مقامی, طور, پر, اسم...\n",
      "8     [گنے, بروقت, کٹائی, چینی, قیمت, کم, 85, روپے, ...\n",
      "9               [نومبر, مہنگائی, معمولی, کمی, 83, فیصد]\n",
      "10         [ڈسکوز, بجلی, ٹیرف, 86, پیسے, اضافے, مطالبہ]\n",
      "11    [جوہری, بجلی, گھر, زمائش, کیلئے, ایندھن, لوڈنگ...\n",
      "12    [پاک, سوزوکی, اور, انڈس, موٹرز, گاڑیوں, قیمتوں...\n",
      "13    [نومبر, ریونیو, وصولی, 346, ارب, روپے, ساتھ, ہ...\n",
      "14       [نیشنل, بینک, تقرریوں, تھرڈ, پارٹی, ڈٹ, سفارش]\n",
      "15             [بٹ, کوائن, قیمت, ریکارڈ, سطح, پر, پہنچ]\n",
      "16    [پیٹرول, قیمت, برقرار, ڈیزل, روپے, فی, لیٹر, م...\n",
      "17    [ئل, کمپنیز, اور, ڈیلرز, مارجن, 16فیصد, تک, اض...\n",
      "18    [مالی, سال, 2020, ملک, موبائل, فون, درامد, پر,...\n",
      "19    [ازادی, بعد, پہلی, مرتبہ, بھارتی, معیشت, کساد,...\n",
      "20    [وائرس, پھیلا, اضافہ, اور, پابندیاں, معاشی, بح...\n",
      "Name: Headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.Headline.apply(text_cleaning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d10455ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'عالمی': 73,\n",
       " 'بینک': 36,\n",
       " 'عسکریت': 74,\n",
       " 'پسندی': 120,\n",
       " 'متاثرہ': 91,\n",
       " 'خاندانوں': 48,\n",
       " 'معاونت': 97,\n",
       " 'کرے': 137,\n",
       " 'گا': 149,\n",
       " 'مالی': 90,\n",
       " 'سال': 62,\n",
       " '2020': 2,\n",
       " 'ریٹرن': 56,\n",
       " 'فائل': 76,\n",
       " 'والوں': 110,\n",
       " 'تعداد': 38,\n",
       " '23': 3,\n",
       " 'فیصد': 80,\n",
       " 'کمی': 143,\n",
       " 'جاپان': 45,\n",
       " 'سندھ': 67,\n",
       " 'خصوصی': 49,\n",
       " 'اقتصادی': 19,\n",
       " 'زون': 60,\n",
       " 'سرمایہ': 64,\n",
       " 'کاری': 135,\n",
       " 'دعوت': 53,\n",
       " 'برامدات': 28,\n",
       " '767': 6,\n",
       " 'بڑھ': 34,\n",
       " 'ارب': 11,\n",
       " '16': 0,\n",
       " 'کروڑ': 136,\n",
       " 'ڈالر': 129,\n",
       " 'زائد': 58,\n",
       " 'الیکٹرک': 21,\n",
       " 'اضافی': 17,\n",
       " 'بجلی': 26,\n",
       " 'گیس': 154,\n",
       " 'فراہمی': 77,\n",
       " 'قانونی': 81,\n",
       " 'تقاضے': 40,\n",
       " 'تعطل': 39,\n",
       " 'شکار': 69,\n",
       " 'کھانے': 146,\n",
       " 'پینے': 125,\n",
       " 'اشیا': 15,\n",
       " 'قیمتیں': 85,\n",
       " 'بلند': 32,\n",
       " 'ترین': 37,\n",
       " 'سطح': 65,\n",
       " 'پر': 119,\n",
       " 'پہنچ': 123,\n",
       " 'گئیں': 148,\n",
       " 'اقوام': 20,\n",
       " 'متحدہ': 92,\n",
       " 'صنعتی': 71,\n",
       " 'صارفین': 70,\n",
       " 'کیلئے': 147,\n",
       " 'پیک': 127,\n",
       " 'ور': 111,\n",
       " 'ٹیرف': 114,\n",
       " 'اسکیم': 14,\n",
       " 'خاتمہ': 47,\n",
       " 'اور': 23,\n",
       " 'سبسڈی': 63,\n",
       " 'منظور': 102,\n",
       " 'پاکستان': 118,\n",
       " 'موبائل': 103,\n",
       " 'کمپنیاں': 141,\n",
       " 'مقامی': 100,\n",
       " 'طور': 72,\n",
       " 'اسمبلنگ': 13,\n",
       " 'جانب': 44,\n",
       " 'گامزن': 150,\n",
       " 'گنے': 152,\n",
       " 'بروقت': 30,\n",
       " 'کٹائی': 145,\n",
       " 'چینی': 128,\n",
       " 'قیمت': 83,\n",
       " 'کم': 140,\n",
       " '85': 8,\n",
       " 'روپے': 54,\n",
       " 'فی': 79,\n",
       " 'کلوگرام': 139,\n",
       " 'تک': 42,\n",
       " 'نومبر': 107,\n",
       " 'مہنگائی': 106,\n",
       " 'معمولی': 98,\n",
       " '83': 7,\n",
       " 'ڈسکوز': 130,\n",
       " '86': 9,\n",
       " 'پیسے': 124,\n",
       " 'اضافے': 18,\n",
       " 'مطالبہ': 95,\n",
       " 'جوہری': 46,\n",
       " 'گھر': 153,\n",
       " 'زمائش': 59,\n",
       " 'ایندھن': 24,\n",
       " 'لوڈنگ': 87,\n",
       " 'غاز': 75,\n",
       " 'پاک': 117,\n",
       " 'سوزوکی': 68,\n",
       " 'انڈس': 22,\n",
       " 'موٹرز': 104,\n",
       " 'گاڑیوں': 151,\n",
       " 'قیمتوں': 84,\n",
       " 'لاکھ': 86,\n",
       " 'اضافہ': 16,\n",
       " 'ریونیو': 55,\n",
       " 'وصولی': 113,\n",
       " '346': 4,\n",
       " 'ساتھ': 61,\n",
       " 'ہدف': 155,\n",
       " 'قریب': 82,\n",
       " 'نیشنل': 108,\n",
       " 'تقرریوں': 41,\n",
       " 'تھرڈ': 43,\n",
       " 'پارٹی': 116,\n",
       " 'ڈٹ': 131,\n",
       " 'سفارش': 66,\n",
       " 'بٹ': 33,\n",
       " 'کوائن': 144,\n",
       " 'ریکارڈ': 57,\n",
       " 'پیٹرول': 126,\n",
       " 'برقرار': 29,\n",
       " 'ڈیزل': 132,\n",
       " 'لیٹر': 88,\n",
       " 'مہنگا': 105,\n",
       " 'ئل': 10,\n",
       " 'کمپنیز': 142,\n",
       " 'ڈیلرز': 133,\n",
       " 'مارجن': 89,\n",
       " '16فیصد': 1,\n",
       " 'متوقع': 93,\n",
       " 'ملک': 101,\n",
       " 'فون': 78,\n",
       " 'درامد': 52,\n",
       " '54': 5,\n",
       " 'ڈیوٹی': 134,\n",
       " 'وصول': 112,\n",
       " 'ازادی': 12,\n",
       " 'بعد': 31,\n",
       " 'پہلی': 122,\n",
       " 'مرتبہ': 94,\n",
       " 'بھارتی': 35,\n",
       " 'معیشت': 99,\n",
       " 'کساد': 138,\n",
       " 'بازاری': 25,\n",
       " 'داخل': 51,\n",
       " 'وائرس': 109,\n",
       " 'پھیلا': 121,\n",
       " 'پابندیاں': 115,\n",
       " 'معاشی': 96,\n",
       " 'بحالی': 27,\n",
       " 'خطرہ': 50}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying CountVectorizer\n",
    "bow_transformer = CountVectorizer(analyzer=text_cleaning).fit(df['Headline'])\n",
    "bow_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ae84d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 36)\t1\n",
      "  (0, 48)\t1\n",
      "  (0, 73)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 91)\t1\n",
      "  (0, 97)\t1\n",
      "  (0, 120)\t1\n",
      "  (0, 137)\t1\n",
      "  (0, 149)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 38)\t1\n",
      "  (1, 56)\t1\n",
      "  (1, 62)\t1\n",
      "  (1, 76)\t1\n",
      "  (1, 80)\t1\n",
      "  (1, 90)\t1\n",
      "  (1, 110)\t1\n",
      "  (1, 143)\t1\n",
      "  (2, 19)\t1\n",
      "  (2, 45)\t1\n",
      "  (2, 49)\t1\n",
      "  (2, 53)\t1\n",
      "  (2, 60)\t1\n",
      "  (2, 64)\t1\n",
      "  :\t:\n",
      "  (18, 78)\t1\n",
      "  (18, 90)\t1\n",
      "  (18, 101)\t1\n",
      "  (18, 103)\t1\n",
      "  (18, 112)\t1\n",
      "  (18, 119)\t1\n",
      "  (18, 134)\t1\n",
      "  (19, 12)\t1\n",
      "  (19, 25)\t1\n",
      "  (19, 31)\t1\n",
      "  (19, 35)\t1\n",
      "  (19, 51)\t1\n",
      "  (19, 94)\t1\n",
      "  (19, 99)\t1\n",
      "  (19, 122)\t1\n",
      "  (19, 138)\t1\n",
      "  (20, 16)\t1\n",
      "  (20, 23)\t1\n",
      "  (20, 27)\t1\n",
      "  (20, 50)\t1\n",
      "  (20, 96)\t1\n",
      "  (20, 109)\t1\n",
      "  (20, 115)\t1\n",
      "  (20, 121)\t1\n",
      "  (20, 147)\t1\n"
     ]
    }
   ],
   "source": [
    "#Showing Vector with Index\n",
    "\n",
    "title_bow = bow_transformer.transform(df['Headline'])\n",
    "print(title_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90c95ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfTransformer()\n",
      "  (0, 149)\t0.3375685826755092\n",
      "  (0, 137)\t0.3375685826755092\n",
      "  (0, 120)\t0.3375685826755092\n",
      "  (0, 97)\t0.3375685826755092\n",
      "  (0, 91)\t0.3375685826755092\n",
      "  (0, 74)\t0.3375685826755092\n",
      "  (0, 73)\t0.3375685826755092\n",
      "  (0, 48)\t0.3375685826755092\n",
      "  (0, 36)\t0.29728709343592985\n",
      "  (1, 143)\t0.30041133371461554\n",
      "  (1, 110)\t0.34111614792842515\n",
      "  (1, 90)\t0.30041133371461554\n",
      "  (1, 80)\t0.2715308084175545\n",
      "  (1, 76)\t0.34111614792842515\n",
      "  (1, 62)\t0.2715308084175545\n",
      "  (1, 56)\t0.34111614792842515\n",
      "  (1, 38)\t0.34111614792842515\n",
      "  (1, 3)\t0.34111614792842515\n",
      "  (1, 2)\t0.30041133371461554\n",
      "  (2, 135)\t0.35355339059327373\n",
      "  (2, 67)\t0.35355339059327373\n",
      "  (2, 64)\t0.35355339059327373\n",
      "  (2, 60)\t0.35355339059327373\n",
      "  (2, 53)\t0.35355339059327373\n",
      "  (2, 49)\t0.35355339059327373\n",
      "  :\t:\n",
      "  (18, 78)\t0.3073609565140677\n",
      "  (18, 62)\t0.24466144304540285\n",
      "  (18, 54)\t0.20798457885277286\n",
      "  (18, 52)\t0.3073609565140677\n",
      "  (18, 11)\t0.24466144304540285\n",
      "  (18, 5)\t0.3073609565140677\n",
      "  (18, 2)\t0.2706840923214377\n",
      "  (19, 138)\t0.3333333333333333\n",
      "  (19, 122)\t0.3333333333333333\n",
      "  (19, 99)\t0.3333333333333333\n",
      "  (19, 94)\t0.3333333333333333\n",
      "  (19, 51)\t0.3333333333333333\n",
      "  (19, 35)\t0.3333333333333333\n",
      "  (19, 31)\t0.3333333333333333\n",
      "  (19, 25)\t0.3333333333333333\n",
      "  (19, 12)\t0.3333333333333333\n",
      "  (20, 147)\t0.28500441975429697\n",
      "  (20, 121)\t0.35804264855153906\n",
      "  (20, 115)\t0.35804264855153906\n",
      "  (20, 109)\t0.35804264855153906\n",
      "  (20, 96)\t0.35804264855153906\n",
      "  (20, 50)\t0.35804264855153906\n",
      "  (20, 27)\t0.35804264855153906\n",
      "  (20, 23)\t0.2614913619036536\n",
      "  (20, 16)\t0.28500441975429697\n",
      "shape =  (21, 156)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(title_bow)\n",
    "print(tfidf_transformer)\n",
    "title_tfidf = tfidf_transformer.transform(title_bow)\n",
    "print(title_tfidf)\n",
    "print(\"shape = \", title_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acf3d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X= title_tfidf\n",
    "y = df['Headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b22987a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elmo = hub.load(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "elmo = MultinomialNB().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9dec132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی معاونت کرے گا'\n",
      " 'مالی سال 2020 ریٹرن فائل کرنے والوں کی تعداد میں 23 فیصد کمی'\n",
      " 'جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ کاری کی دعوت'\n",
      " 'برامدات 767 فیصد بڑھ کر ارب 16 کروڑ ڈالر سے زائد'\n",
      " 'کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانونی تقاضے تعطل کا شکار'\n",
      " 'کھانے پینے کی اشیا کی قیمتیں سال کی بلند ترین سطح پر پہنچ گئیں اقوام متحدہ'\n",
      " 'صنعتی صارفین کیلئے بجلی کے پیک ور ٹیرف اسکیم کا خاتمہ اور سبسڈی منظور'\n",
      " 'پاکستان میں موبائل کمپنیاں مقامی طور پر اسمبلنگ کی جانب گامزن'\n",
      " 'گنے کی بروقت کٹائی سے چینی کی قیمت کم ہو کر 85 روپے فی کلوگرام تک پہنچ گئی'\n",
      " 'نومبر میں مہنگائی معمولی کمی سے 83 فیصد رہی'\n",
      " 'ڈسکوز کا بجلی کے ٹیرف میں 86 پیسے اضافے کا مطالبہ'\n",
      " 'جوہری بجلی گھر کی زمائش کیلئے ایندھن کی لوڈنگ کا غاز'\n",
      " 'پاک سوزوکی اور انڈس موٹرز کی گاڑیوں کی قیمتوں میں ایک لاکھ روپے تک اضافہ'\n",
      " 'نومبر میں ریونیو کی وصولی 346 ارب روپے کے ساتھ ہدف سے قریب رہی'\n",
      " 'نیشنل بینک میں تقرریوں کے تھرڈ پارٹی ڈٹ کی سفارش'\n",
      " 'بٹ کوائن کی قیمت ریکارڈ سطح پر پہنچ گئی'\n",
      " 'پیٹرول کی قیمت برقرار ڈیزل روپے فی لیٹر مہنگا'\n",
      " 'ئل کمپنیز اور ڈیلرز کے مارجن میں 16فیصد تک اضافہ متوقع'\n",
      " 'مالی سال 2020 ملک میں موبائل فون کی درامد پر 54 ارب روپے کی ڈیوٹی وصول'\n",
      " 'ازادی کے بعد پہلی مرتبہ بھارتی معیشت کساد بازاری میں داخل'\n",
      " 'وائرس کے پھیلا میں اضافہ اور پابندیاں معاشی بحالی کیلئے خطرہ']\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "all_predictions = elmo.predict(X)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3db1d83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y,all_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc190899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33952dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
